{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iliodipietro/AIML_Project/blob/master/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QcGnGPdX2C",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9O3aM3Tb28q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.4.2'\n",
        "!pip3 uninstall 'Pillow-SIMD'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\n",
        "!pip install --upgrade pillow\n",
        "\n",
        "!pip uninstall 'tensorflow==2.0.0'\n",
        "!pip install 'tensorflow'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import logging\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from   matplotlib.pyplot import subplots\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet #serve? \n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd \n",
        "\n",
        "import re\n",
        "import urllib\n",
        "from urllib import request, error\n",
        "from urllib.request import urlopen, HTTPError\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import sys, requests, shutil\n",
        "from shutil import copyfile\n",
        "\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "\n",
        "#togliere nel caso non usassimo piu la classe landmark\n",
        "from torchvision.datasets import VisionDataset\n",
        "import os.path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-xpI7nKLfwY",
        "colab_type": "text"
      },
      "source": [
        "**Loading the dataset from Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMUKYOPmkY1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transformation for TRANSFER LEARNING, based on the ImageNet dataset\n",
        "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
        "train_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.RandomCrop(224),\n",
        "                                      transforms.RandomRotation(20),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      normalize,])\n",
        "\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      normalize,])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DayyAhXb5ckt",
        "colab_type": "text"
      },
      "source": [
        "**Plot data distribution and filter num.classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVjt9RBy5eoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import csv files containing dataset data structure \n",
        "#each row of the file contains 'id,URL,Landmark_ID'. First row is the header of the file\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/Progetto_AIML/dataset/train.csv')      #('/content/Project_AIML/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/My Drive/Progetto_AIML/dataset/test.csv')    #('/content/Project_AIML/test.csv')\n",
        "data.head(5)\n",
        "\n",
        "#DATA SAMPLES\n",
        "#study distributions of data from selected filtered classes 1000 - 1299\n",
        "\n",
        "#we define a list of labels from 1000 to 1299\n",
        "landmark_list = [str(x) for x in list(range(1000,1300))]\n",
        "#which images stored in data match the landmark ID from 1000 to 1299? check it with data.isin(landmark_list)\n",
        "data_sample = data[data['landmark_id'].isin(landmark_list)]\n",
        "# data_sample.landmark_id.value_counts()\n",
        "print(len(data_sample))\n",
        "# Check data distribution\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "colors = np.array(['#4285f4','#34a853','#fbbc05','#ea4335'])\n",
        "#Define the order in which to display the graph\n",
        "order = ['1-5','5-10','10-50','50-100','100-200','200-500','>=500']\n",
        "f, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))\n",
        "\n",
        "\n",
        "def plot_distribution(data_f, data_k, axis):\n",
        "    #data['landmark_id'].value_counts()\n",
        "    x=data_f.landmark_id.value_counts().index\n",
        "    y=pd.DataFrame(data_f.landmark_id.value_counts())\n",
        "\n",
        "    #Create a variable to group the number of image sin each class\n",
        "    y['Number of images'] = np.where(y['landmark_id']>=500,'>=500',y['landmark_id'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=200) & (y['landmark_id']<500),'200-500',y['Number of images'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=100) & (y['landmark_id']<200),'100-200',y['Number of images'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=50) & (y['landmark_id']<100),'50-100',y['Number of images'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=10) & (y['landmark_id']<50),'10-50',y['Number of images'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=5) & (y['landmark_id']<10),'5-10',y['Number of images'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=0) & (y['landmark_id']<5),'1-5',y['Number of images'])\n",
        "\n",
        "    y['Number of images'].value_counts().loc[order].plot(kind = 'bar',color = colors,width = 0.8, ax=axis, fontsize = 14)\n",
        "    axis.set_xlabel('Number of images', fontsize = 18)\n",
        "    axis.set_ylabel('Number of classes', fontsize = 18)\n",
        "    axis.grid()\n",
        "    axis.set_title(data_k, fontsize = 18)\n",
        "    \n",
        "plot_distribution(data, 'Total', ax1)\n",
        "plot_distribution(data_sample, 'Filtered', ax2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt7m0Hc4TXT3",
        "colab_type": "text"
      },
      "source": [
        " **Display Photo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56hK-WGuTFdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def displayLandmarkImagesLarge(urls, category_name):\n",
        "    img_style = \"width: 200px; height:160px; margin: 0px; float: left; border: 1px solid black;\"\n",
        "    images_list = ''.join([f\"<img style='{img_style}' src='{u}' />\" for _, u in urls.head(12).iteritems()])\n",
        "    display(HTML(images_list))\n",
        "\n",
        "\n",
        "category = data['landmark_id'].value_counts().keys()[15]\n",
        "urls = data[data['landmark_id'] == category]['url']\n",
        "displayLandmarkImagesLarge(urls, \"\")\n",
        "\n",
        "# Visualize 5 images for each of the first 4 landmarks, ordered by the number of occurences.\n",
        "LANDMARK_NUMBER = 10\n",
        "IMAGES_NUMBER = 15\n",
        "landMarkIDs = pd.Series(data['landmark_id'].value_counts().keys())[0:LANDMARK_NUMBER]\n",
        "for landMarkID in landMarkIDs:\n",
        "    url = data[data['landmark_id'] == landMarkID]['url'].head(IMAGES_NUMBER)\n",
        "    displayLandmarkImagesLarge(url, \"\")\n",
        "\n",
        "pd.Series(data['landmark_id'].value_counts().keys())[1:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5inz0TagAX5M",
        "colab_type": "text"
      },
      "source": [
        "**Delete folders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU3BdldPAbnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deleteFolder(directory): \n",
        "  try:\n",
        "      if os.path.exists(directory):\n",
        "        for filename in os.listdir(directory):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            try:\n",
        "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                    os.unlink(file_path)\n",
        "                elif os.path.isdir(file_path):\n",
        "                    shutil.rmtree(file_path)\n",
        "            except Exception as e:\n",
        "                print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "        \n",
        "        os.removedirs(directory)\n",
        "  except  Exception as e:\n",
        "      print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "deleteFolder('/content/Data') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T03o9-Z5xP0u",
        "colab_type": "text"
      },
      "source": [
        "**Create folders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IP90DNKxS5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSError:\n",
        "        print ('Error: Creating directory. ' +  directory)\n",
        "createFolder('/content/Data')        \n",
        "createFolder('/content/Data/test_images_from_train')\n",
        "createFolder('/content/Data/train_images_model')\n",
        "createFolder('/content/Data/validation_images_model')  \n",
        "createFolder('/content/Data/test_images')  \n",
        "createFolder('/content/Data/train_images_model_resize')   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW6dJCX7E_gk",
        "colab_type": "text"
      },
      "source": [
        "**Create lists for test, train and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB8ckvSPFGnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TARGET_SIZE = 128 #imports images of resolution 128x128\n",
        "\n",
        "#change URLs to resize images to target size\n",
        "def overwrite_urls(df):\n",
        "    def reso_overwrite(url_tail, reso=TARGET_SIZE):\n",
        "        pattern = 's[0-9]+'\n",
        "        search_result = re.match(pattern, url_tail)\n",
        "        if search_result is None:\n",
        "            return url_tail\n",
        "        else:\n",
        "            return 's{}'.format(reso)\n",
        "    \n",
        "    def join_url(parsed_url, s_reso):\n",
        "        parsed_url[-2] = s_reso\n",
        "        return '/'.join(parsed_url)\n",
        "    \n",
        "    df = df[df.url.apply(lambda x: len(x.split('/'))>1)]\n",
        "    parsed_url = df.url.apply(lambda x: x.split('/'))\n",
        "    train_url_tail = parsed_url.apply(lambda x: x[-2])\n",
        "    resos = train_url_tail.apply(lambda x: reso_overwrite(x, reso=TARGET_SIZE))\n",
        "\n",
        "    overwritten_df = pd.concat([parsed_url, resos], axis=1)\n",
        "    overwritten_df.columns = ['url', 's_reso']\n",
        "    df['url'] = overwritten_df.apply(lambda x: join_url(x['url'], x['s_reso']), axis=1)\n",
        "    return df\n",
        "\n",
        "data_sample_resize = overwrite_urls(data_sample)\n",
        "print ('1. URLs overwritten')\n",
        "\n",
        "\n",
        "'''Split to test and train'''\n",
        "data_test = pd.DataFrame(columns = ['id','url','landmark_id'])\n",
        "data_training_all = pd.DataFrame(columns = ['id','url','landmark_id'])\n",
        "#percent_test = 0.01 #takes 1% from each class as holdout data\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "for landmark_id in set(data_sample_resize['landmark_id']):\n",
        "    #directory = os.path.join(basepath, 'landmark_id') \n",
        "    #createFolder(directory)\n",
        "    #os.chdir(directory) \n",
        " \n",
        "    n = 1\n",
        "    t = data_sample_resize[(data_sample_resize.landmark_id == landmark_id)] #get all images for a landmark id\n",
        "    \n",
        "    if(len(t.id) <= 10):\n",
        "      percent_test = 0.25\n",
        "    else:\n",
        "      if(len(t.id) > 10 and len(t.id) <= 100):\n",
        "        percent_test = 0.05\n",
        "      else:\n",
        "        percent_test = 0.01\n",
        "    \n",
        "    i = 0\n",
        "    r =[]\n",
        "    while i < len(t.id):\n",
        "        it = i\n",
        "        try:\n",
        "          ret = urlopen(t.url.iloc[it])\n",
        "          r.append(t.id.iloc[it])  #create a list of all these images\n",
        "          i += 1\n",
        "        except HTTPError:\n",
        "          i += 1\n",
        "        \n",
        "    test = random.sample(r, int(percent_test*len(r))) #randomly pick a sample of 1% images from list 'r'\n",
        "    training = list(set(r) - set(test))  #get the remaining images\n",
        "    data_t = data_sample_resize[data_sample_resize.id.isin(test)] #holdout dataset\n",
        "    data_tr = data_sample_resize[data_sample_resize.id.isin(training)] #training dataset\n",
        "    data_test = data_test.append(data_t)  \n",
        "    data_training_all = data_training_all.append(data_tr)\n",
        "    n+=1\n",
        "\n",
        "print ('2. train and test set created')\n",
        "\n",
        "\n",
        "'''Split into train and validation set'''\n",
        "data_valid = pd.DataFrame(columns = ['id','url','landmark_id'])\n",
        "data_train = pd.DataFrame(columns = ['id','url','landmark_id'])\n",
        "percent_validation = 0.2 #takes 20% from each class as holdout data\n",
        "\n",
        "random.seed(42)\n",
        "for landmark_id in set(data_training_all['landmark_id']):\n",
        "    n=1\n",
        "    t = data_training_all[(data_training_all.landmark_id == landmark_id)]\n",
        "    i = 0\n",
        "    r =[]\n",
        "    while i < len(t.id):\n",
        "        it = i\n",
        "        r.append(t.id.iloc[it])\n",
        "        i += 1\n",
        "        \n",
        "    valid = random.sample(r,int(percent_validation*len(r)))\n",
        "    train = list(set(r) - set(valid)) \n",
        "    data_v = data_training_all[data_training_all.id.isin(valid)]\n",
        "    data_t = data_training_all[data_training_all.id.isin(train)]\n",
        "    data_valid = data_valid.append(data_v)\n",
        "    data_train = data_train.append(data_t)\n",
        "    n+=1\n",
        "\n",
        "print ('3. train and validation set created')\n",
        "\n",
        "data_test = data_test.sort_values(by = ['landmark_id', 'id'])\n",
        "print(data_test)\n",
        "subfile = '/content/Data/test.csv'\n",
        "with open(subfile, 'w') as csvfile:\n",
        "  csvfile.write('id,url\\n')\n",
        "  i = 0\n",
        "  for id in data_test['id']:\n",
        "    csvfile.write('{0},{1}\\n'.format(id,data_test['url'].iloc[i] ))\n",
        "    i += 1\n",
        "print('test.csv created')    \n",
        "print (len(data_train))\n",
        "print (len(data_valid))\n",
        "print (len(data_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KblVzj0puYA9",
        "colab_type": "text"
      },
      "source": [
        "**Check data distribution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKCmQSuR0krV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check data distribution\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "colors = np.array(['#4285f4','#34a853','#fbbc05','#ea4335'])\n",
        "#Define the order in which to display the graph\n",
        "order = ['1-5','5-10','10-50','50-100','100-200','200-500','>=500']\n",
        "f, (ax1, ax2,ax3) = plt.subplots(1, 3,figsize=(15,5))\n",
        "\n",
        "\n",
        "def plot_distribution(data_f, data_k, axis):\n",
        "    #data['landmark_id'].value_counts()\n",
        "    x=data_f.landmark_id.value_counts().index\n",
        "    y=pd.DataFrame(data_f.landmark_id.value_counts())\n",
        "\n",
        "    #Create a variable to group the number of image sin each class\n",
        "    y['Number of images'] = np.where(y['landmark_id']>=500,'>=500',y['landmark_id'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=200) & (y['landmark_id']<500),'200-500',y['Number of images'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=100) & (y['landmark_id']<200),'100-200',y['Number of images'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=50) & (y['landmark_id']<100),'50-100',y['Number of images'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=10) & (y['landmark_id']<50),'10-50',y['Number of images'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=5) & (y['landmark_id']<10),'5-10',y['Number of images'])\n",
        "    y['Number of images'] = np.where((y['landmark_id']>=0) & (y['landmark_id']<5),'1-5',y['Number of images'])\n",
        "\n",
        "    y['Number of images'].value_counts().loc[order].plot(kind = 'bar',color = colors,width = 0.8, ax=axis)\n",
        "    axis.set_xlabel('Number of images')\n",
        "    axis.set_ylabel('Number of classes')\n",
        "    axis.set_title(data_k)\n",
        "    \n",
        "plot_distribution(data_train, 'Training', ax1)\n",
        "plot_distribution(data_valid, 'Validation', ax2)\n",
        "plot_distribution(data_sample, 'Filtered Classes', ax3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al8C-eYeInro",
        "colab_type": "text"
      },
      "source": [
        "**Fetch images in folders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4b1K2mvImTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remember to create the three folders for train-validation-test inside your Data directoy in order to be able to execute this code!\n",
        "def fetch_image(path,folder):\n",
        "    url = path\n",
        "    response=requests.get(url, stream = True)\n",
        "    with open('/content/Data/' + folder + '/image.jpg', 'wb') as out_file:\n",
        "        shutil.copyfileobj(response.raw, out_file)\n",
        "    del response\n",
        "    \n",
        "    \n",
        "'''TRAIN SET - fetch images for the resized URLs and save in the already created directory train_images_model'''\n",
        "i=0\n",
        "for link in data_train['url']:              #looping over links to get images\n",
        "    if os.path.exists('/content/Data/train_images_model/'+str(data_train['id'].iloc[i])+'.jpg'):\n",
        "        i+=1\n",
        "        continue\n",
        "    fetch_image(link, 'train_images_model')\n",
        "    os.rename('/content/Data/train_images_model/image.jpg', '/content/Data/train_images_model/' + str(data_train['id'].iloc[i]) + '.jpg')\n",
        "    i+=1\n",
        "#    if(i==50):   #uncomment to test in your machine\n",
        "#        break\n",
        "print('4. Train images fetched')\n",
        "\n",
        "    \n",
        "i=0\n",
        "for link in data_valid['url']:              #looping over links to get images\n",
        "    if os.path.exists('/content/Data/validation_images_model/' + str(data_valid['id'].iloc[i]) + '.jpg'):\n",
        "        i += 1 \n",
        "        continue\n",
        "    fetch_image(link, 'validation_images_model')\n",
        "    os.rename('/content/Data/validation_images_model/image.jpg', '/content/Data/validation_images_model/' + str(data_valid['id'].iloc[i]) + '.jpg')\n",
        "    i += 1\n",
        "#    if(i==50):   #uncomment to test in your machine\n",
        "#        break\n",
        "print('5. Validation images fetched')\n",
        "\n",
        "i = 0\n",
        "for link in data_test['url']:              #looping over links to get images\n",
        "    if os.path.exists('/content/Data/test_images_from_train/' + str(data_test['id'].iloc[i]) + '.jpg'):\n",
        "        i += 1\n",
        "        continue\n",
        "    fetch_image(link, 'test_images_from_train')\n",
        "    os.rename('/content/Data/test_images_from_train/image.jpg', '/content/Data/test_images_from_train/' + str(data_test['id'].iloc[i]) + '.jpg')\n",
        "    i += 1\n",
        "#    if(i==50):   #uncomment to test in your machine\n",
        "#        break\n",
        "print('6. Test images from train fetched')\n",
        "\n",
        "i=0\n",
        "for link in data_test['url']:              #looping over links to get images\n",
        "    #print(data_test['id'].iloc[i])\n",
        "    if os.path.exists('/content/Data/test_images/' + str(data_test['id'].iloc[i]) + '.jpg'):\n",
        "        i += 1\n",
        "        continue\n",
        "    fetch_image(link, 'test_images')\n",
        "    os.rename('/content/Data/test_images/image.jpg', '/content/Data/test_images/' + str(data_test['id'].iloc[i]) + '.jpg')\n",
        "    i += 1\n",
        "print('7. Test images fetched')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kJbyFBY0XVa",
        "colab_type": "text"
      },
      "source": [
        "**Visualization of images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhyXHzgklOaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize 5 images for each of the first 4 landmarks, ordered by the number of occurences.\n",
        "\n",
        "IDs = pd.Series(data_train['id'].value_counts().keys())[0:5]\n",
        "for ID in IDs:\n",
        "    url = data_train[data_train['id'] == ID]['url']\n",
        "    displayLandmarkImagesLarge(url, \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs8HMz-N8lo7",
        "colab_type": "text"
      },
      "source": [
        "**Create subfolders for landmark_ID**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siUImk_P8kq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##create folders for landmark IDs in Training folder\n",
        "train_data = data_train\n",
        "\n",
        "temp = pd.DataFrame(data_train.landmark_id.value_counts())\n",
        "temp.reset_index(inplace = True)\n",
        "temp.columns = ['landmark_id', 'count']\n",
        "\n",
        "def createfolders(dataset, folder):\n",
        "    i = 0\n",
        "    while i < len(dataset):\n",
        "        landmark = str(dataset.landmark_id.iloc[i])\n",
        "        path = '/content/Data/' + folder + '/' + landmark\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "        i += 1\n",
        "createfolders(temp, 'train_images_model')\n",
        "#make folders for landmark ID which had no images in training sets - required for codes running next\n",
        "available = [int((x[0].split('/'))[-1]) for x in os.walk(r'/content/Data/train_images_model/') if len((x[0].split('/'))[-1]) > 0]\n",
        "new = [str(x) for x in range(1000,1300) if x not in available]\n",
        "for i in new:\n",
        "    path = '/content/Data/train_images_model/' + i\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "print ('Train folders created')\n",
        "\n",
        "rootdirpics = r'/content/Data/train_images_model/'\n",
        "rootdirfolders = r'/content/Data/train_images_model/'\n",
        "\n",
        "def transformdata(data,path1, path2):\n",
        "\n",
        "    n = 1\n",
        "    for landmark_id in set(data['landmark_id']):\n",
        "        t = data[(data.landmark_id == landmark_id)]\n",
        "        i = 1\n",
        "        r = []\n",
        "        while i <= len(t.id):\n",
        "            it = i - 1\n",
        "            r.append(t.id.iloc[it])\n",
        "            i += 1\n",
        "        for files in os.listdir(rootdirpics):    # loop through startfolders\n",
        "            inpath = path1 + files\n",
        "            folder = str(landmark_id)\n",
        "            outpath = path2 + folder  \n",
        "            if ((files.split('.')[0] in r) & (os.path.getsize(inpath) >1000)):\n",
        "#                 print('move')\n",
        "                shutil.move(inpath, outpath)\n",
        "            elif ((files.split('.')[0] in r) & (os.path.getsize(inpath) <= 1000)):\n",
        "                os.remove(inpath)\n",
        "        n += 1\n",
        "\n",
        "transformdata(train_data,rootdirpics, rootdirfolders)\n",
        "print ('Train images moved')\n",
        "\n",
        "##create folders for landmark IDs in Validation folder\n",
        "\n",
        "temp = pd.DataFrame(data_valid.landmark_id.value_counts())\n",
        "temp.reset_index(inplace = True)\n",
        "temp.columns = ['landmark_id', 'count']\n",
        "createfolders(temp, 'validation_images_model')\n",
        "print ('Validation folders created')\n",
        "\n",
        "#make folders for landmark ID which had no images in validation sets - required for codes running next\n",
        "available = [int((x[0].split('/'))[-1]) for x in os.walk(r'/content/Data/validation_images_model/') if len((x[0].split('/'))[-1]) > 0]\n",
        "new = [str(x) for x in range(1000,1300) if x not in available]\n",
        "for i in new:\n",
        "    path = '/content/Data/validation_images_model/' + i\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "rootdirpics = r'/content/Data/validation_images_model/'\n",
        "rootdirfolders = r'/content/Data/validation_images_model/'\n",
        "transformdata(data_valid,rootdirpics, rootdirfolders)\n",
        "print ('Validation images moved')\n",
        "\n",
        "##create folders for landmark IDs in Test folder (required for creating dataset with ImageFolder)\n",
        "\n",
        "temp = pd.DataFrame(data_test.landmark_id.value_counts())\n",
        "temp.reset_index(inplace = True)\n",
        "temp.columns = ['landmark_id','count']\n",
        "createfolders(temp,'test_images_from_train')\n",
        "print ('Test folders created')\n",
        "\n",
        "#make folders for landmark ID which had no images in validation sets - required for codes running next\n",
        "available = [int((x[0].split('/'))[-1]) for x in os.walk(r'/content/Data/test_images_from_train/') if len((x[0].split('/'))[-1]) > 0]\n",
        "new = [str(x) for x in range(1000,1300) if x not in available]\n",
        "for i in new:\n",
        "    path = '/content/Data/test_images_from_train/' + i\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "rootdirpics = r'/content/Data/test_images_from_train/'\n",
        "rootdirfolders = r'/content/Data/test_images_from_train/'\n",
        "transformdata(data_test,rootdirpics, rootdirfolders)\n",
        "print ('Test images moved')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' \n",
        "\n",
        "NUM_CLASSES = len(landmark_list)\n",
        "print('num classes: {}'.format(NUM_CLASSES))\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "LR = 1e-2       \n",
        "MOMENTUM = 0.9      \n",
        "WEIGHT_DECAY = 5e-5 \n",
        "\n",
        "NUM_EPOCHS = 10      \n",
        "STEP_SIZE = 8       \n",
        "GAMMA = 0.1          \n",
        "\n",
        "LOG_FREQUENCY = 10\n",
        "\n",
        "NUM_IMAGES_PER_FILE = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare Pytorch train/test Datasets\n",
        "\n",
        "DATA_DIR_training = '/content/Data/train_images_model/'\n",
        "DATA_DIR_validation = '/content/Data/validation_images_model/'\n",
        "DATA_DIR_test= '/content/Data/test_images_from_train/'\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(DATA_DIR_training, transform=train_transform)\n",
        "val_dataset = torchvision.datasets.ImageFolder(DATA_DIR_validation, transform=eval_transform)\n",
        "test_dataset = torchvision.datasets.ImageFolder(DATA_DIR_test, transform=eval_transform)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(train_dataset.__len__()))#len(train_dataset)))\n",
        "print('Test Dataset: {}'.format(test_dataset.__len__()))#len(test_dataset)))\n",
        "print('Validation Dataset: {}'.format(val_dataset.__len__()))#len(val_dataset)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGto59Ka0vu3",
        "colab_type": "text"
      },
      "source": [
        "**Check Empty folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tl6Pu97RkCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = -1\n",
        "check = 0\n",
        "for i in range(len(train_dataset)):\n",
        "\n",
        "  if count != train_dataset.__getitem__(i)[1]:\n",
        "    \n",
        "    if check != train_dataset.__getitem__(i)[1]:\n",
        "      print('check = %d - label = %d'%(check, (((train_dataset.__getitem__(i)[1])))))\n",
        "      check += 1\n",
        "    #print('%d' %i)\n",
        "    count = train_dataset.__getitem__(i)[1]\n",
        "    check += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4, drop_last = True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False, num_workers = 4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 25, shuffle = False, num_workers = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZ1t5Qs2z4j",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHUjtXa22DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define resnet50 pre-trained on ImageNet dataset\n",
        "net = torch.hub.load('pytorch/vision:v0.4.2','resnet50', pretrained = True)\n",
        "net.fc = nn.Linear(2048, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "parameters_to_optimize = net.parameters() \n",
        "\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr = LR, momentum = MOMENTUM, weight_decay = WEIGHT_DECAY)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = STEP_SIZE, gamma = GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDTDC-ZNnSH2",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XJ61TCO77uT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function is used for the computation of the accuracy where needed in the following sections\n",
        "def test_accuracy(net, dataloader, type_of_set):  # net=model, dataloader=iterable obj\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net.train(False)  #net.eval()  # important for deactivating dropout and correctly use batchnorm accumulated statistics\n",
        "    with torch.no_grad(): #temporarily set all the requires_grad flag to false\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            outputs = net(images)  # predictions\n",
        "            _, predicted = torch.max(outputs.data, 1)  # predicted labels\n",
        "            total += labels.size(0)\n",
        "            correct += torch.sum(predicted == labels.data).data.item()  # compare with ground truth\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Accuracy of the network on the %s set: %d %%' %(type_of_set, accuracy))\n",
        "    net.train(True)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = net.to(DEVICE) \n",
        "\n",
        "cudnn.benchmark \n",
        "n_epoch = NUM_EPOCHS\n",
        "losses = np.empty(n_epoch)\n",
        "j = 0\n",
        "current_step = 0\n",
        "accuracies_train = np.empty(n_epoch)\n",
        "accuracies_val =  np.empty(n_epoch)\n",
        "n_loss_print = len(train_dataloader)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "  # Start iterating over the epochs\n",
        "for epoch in range(n_epoch):\n",
        "  running_loss = 0.0\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, n_epoch, scheduler.get_lr()))\n",
        "  # Iterate over the dataset\n",
        "  for images, labels in train_dataloader:\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train() \n",
        "\n",
        "    optimizer.zero_grad() \n",
        "\n",
        "    outputs = net(images)\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss += loss.item()\n",
        "    \n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "    loss.backward()  \n",
        "    optimizer.step() \n",
        "\n",
        "    current_step += 1\n",
        "  \n",
        "  \n",
        "  losses[j] = running_loss / n_loss_print\n",
        "  accuracies_train[j] = test_accuracy(net, train_dataloader, 'train')  # at each epoch\n",
        "\n",
        "  #EVALUATION ON VALIDATION\n",
        "  accuracies_val[j] = test_accuracy(net, val_dataloader, 'validation')  # at each epoch\n",
        "  j += 1\n",
        "\n",
        "  # Step the scheduler\n",
        "  scheduler.step() \n",
        "\n",
        "\n",
        "#plot\n",
        "Num_epochs= np.linspace(1,n_epoch,n_epoch)\n",
        "plt.plot(Num_epochs, accuracies_train, 'r')\n",
        "plt.plot(Num_epochs, accuracies_val,   'g')\n",
        "plt.legend(loc='best', labels = ('Accuracy on Train', 'Accuracy on Validation') )\n",
        "plt.xlabel('n epochs')\n",
        "plt.title('Accuracy on train and validation set')\n",
        "plt.grid()\n",
        "plt.show() \n",
        "plt.plot(Num_epochs, losses,'b', label = 'Training Loss') \n",
        "plt.xlabel('n epochs')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Loss on training set')\n",
        "plt.grid()\n",
        "plt.show()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsHFI-GAJd69",
        "colab_type": "text"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO3HV5pqJg1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = net.to(DEVICE) \n",
        "net.train(False) # Set Network to evaluation mode\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle = False, num_workers = 4)\n",
        "running_corrects = 0\n",
        "predictions = []\n",
        "Prob = []\n",
        "GT = []\n",
        "bs = 1\n",
        "for images, labels in tqdm(test_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  for j in range(bs):\n",
        "   GT.append(labels[j].data.item())\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  sm = torch.nn.Softmax()\n",
        "  probabilities = sm(outputs)\n",
        "  #print(probabilities)\n",
        "  top = torch.topk(probabilities, 1)\n",
        "  #print(top.values)\n",
        "  for j in range(bs):\n",
        "    Prob.append(top.values[j].data.item())\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "  for j in range(bs):\n",
        "    predictions.append(preds[j].data.item())\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "print('Test Accuracy: {}%'.format(accuracy * 100))\n",
        "print(predictions)\n",
        "print(GT)\n",
        "print(Prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVY2vIL0tWN5",
        "colab_type": "text"
      },
      "source": [
        "**Submit predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTwiuURkWlBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subfile1 = '/content/Data/sub_spezifinal.csv'\n",
        "\n",
        "test = pd.read_csv('/content/Data/test.csv')\n",
        "\n",
        "def create_predictions_csv(predictions, test_set_list):\n",
        "    print ('starting...')\n",
        "    file_len = len(test_set_list)\n",
        "    print('Number of Test images:', file_len)\n",
        "    \n",
        "    j = 0\n",
        "    prediction_list=[]\n",
        "    for j in range(len(predictions)):\n",
        "      prediction_list.append(predictions[j] + 1000)\n",
        "    #print(prediction_list)\n",
        "    \n",
        "    k = 0 #contatore della lunghezza di prediction_list \n",
        "    num_csv = len(prediction_list) / NUM_IMAGES_PER_FILE\n",
        "    print('divisione iniziale: ', num_csv)\n",
        "    num_csv = int(num_csv)\n",
        "    if len(prediction_list) % NUM_IMAGES_PER_FILE > 0:\n",
        "      num_csv += 1 \n",
        "    print('numero di file da creare: ',num_csv)\n",
        "\n",
        "    splitted_subfile = subfile1.split('.')[0] #/content/Data/sub_spezifinal\n",
        "    for num in range(0, num_csv):\n",
        "      csv_to_open = splitted_subfile + str(num + 1) + '.csv'  #/content/Data/sub_spezifinal1.csv, /content/Data/sub_spezifinal2.csv ...\n",
        "      print(csv_to_open)\n",
        "      with open(csv_to_open, 'w') as csvfile:\n",
        "          csvfile.write('id,landmark,match,prob\\n')\n",
        "          for i in range(0, NUM_IMAGES_PER_FILE):\n",
        "            if(k < len(prediction_list)):\n",
        "              id = test['id'][k]\n",
        "              landmark = prediction_list[k]\n",
        "              prob = Prob[k]\n",
        "              csvfile.write('{0},{1},N,{2}\\n'.format(id, landmark, prob))\n",
        "              k += 1\n",
        "\n",
        "create_predictions_csv(predictions, data_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1BrflJY7AIv",
        "colab_type": "text"
      },
      "source": [
        "**DELF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l-Ig2uWFnA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "from scipy.spatial import cKDTree\n",
        "from skimage.feature import plot_matches\n",
        "from skimage.measure import ransac\n",
        "from skimage.transform import AffineTransform\n",
        "from six import BytesIO\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from six.moves.urllib.request import urlopen\n",
        "from statistics import mean\n",
        "\n",
        "import glob\n",
        "import os\n",
        "from itertools import accumulate\n",
        "import pandas as pd\n",
        "from pandas import Series,DataFrame\n",
        "\n",
        "def DELF(input_file, output_file):\n",
        "  np.random.seed(10)\n",
        "  pred = pd.read_csv(input_file) #csv file containing predictions for test images from neural network\n",
        "  subfile = output_file\n",
        "\n",
        "  with open(subfile, 'w') as csvfile:\n",
        "    csvfile.write('id,landmark,match,prob\\n')\n",
        "    for zoro in range(0, len(pred.index)):\n",
        "        class_folder = str(pred['landmark'][zoro])  #class_folder =  '1070'\n",
        "        test_image_id = str(pred['id'][zoro])       #test_image_id = '5f516881e61501c4'\n",
        "        prob = pred['prob'][zoro]                   #prob = 0.2625 \n",
        "        \n",
        "        def resize_image(srcfile, destfile, new_width = 256, new_height = 256):\n",
        "            pil_image = Image.open(srcfile)\n",
        "            pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "            pil_image_rgb = pil_image.convert('RGB')\n",
        "            pil_image_rgb.save(destfile, format = 'JPEG', quality = 90)\n",
        "            return destfile\n",
        "        def resize_images_folder(srcfolder, destfolder='/content/Data/train_images_model_resize/%s'%(class_folder), new_width = 256, new_height = 256):\n",
        "            os.makedirs(destfolder,exist_ok=True)\n",
        "            for srcfile in glob.iglob(os.path.join('/content/Data/train_images_model/%s'%(class_folder), '*.[Jj][Pp][Gg]')):\n",
        "                src_basename = os.path.basename(srcfile)\n",
        "                destfile = os.path.join(destfolder,src_basename)\n",
        "                resize_image(srcfile, destfile, new_width, new_height)\n",
        "            return destfolder\n",
        "    ###########################################################################################################################\n",
        "        def get_resized_db_image_paths(destfolder = '/content/Data/train_images_model_resize/%s'%(class_folder)):\n",
        "            return sorted(list(glob.iglob(os.path.join(destfolder, '*.[Jj][Pp][Gg]'))))\n",
        "\n",
        "            \n",
        "        resize_images_folder('/content/Data/train_images_model/%s'%(class_folder))\n",
        "        db_images = get_resized_db_image_paths() ## list of image paths\n",
        "\n",
        "        tf.reset_default_graph()\n",
        "        tf.logging.set_verbosity(tf.logging.FATAL)\n",
        "\n",
        "        m = hub.Module('https://tfhub.dev/google/delf/1')\n",
        "\n",
        "        # The module operates on a single image at a time, so define a placeholder to\n",
        "        # feed an arbitrary image in.\n",
        "        image_placeholder = tf.placeholder(\n",
        "            tf.float32, shape = (None, None, 3), name = 'input_image')\n",
        "\n",
        "        module_inputs = {\n",
        "            'image': image_placeholder,\n",
        "            'score_threshold': 100.0,\n",
        "            'image_scales': [0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0],\n",
        "            'max_feature_num': 1000,\n",
        "        }\n",
        "\n",
        "        module_outputs = m(module_inputs, as_dict=True)\n",
        "\n",
        "        def image_input_fn(image_files):\n",
        "          filename_queue = tf.train.string_input_producer(\n",
        "              image_files, shuffle = False)\n",
        "          reader = tf.WholeFileReader()\n",
        "          _, value = reader.read(filename_queue)\n",
        "          image_tf = tf.image.decode_jpeg(value, channels=3)\n",
        "          return tf.image.convert_image_dtype(image_tf, tf.float32)\n",
        "\n",
        "        try:\n",
        "          image_tf = image_input_fn(db_images) ##  training images path list inputted\n",
        "        except ValueError:\n",
        "          continue\n",
        "          \n",
        "        with tf.train.MonitoredSession() as sess:\n",
        "            results_dict = {}  # Stores the locations and their descriptors for each image\n",
        "            for image_path in db_images:\n",
        "                image = sess.run(image_tf)\n",
        "                #print('Extracting locations and descriptors from %s' % image_path)\n",
        "                results_dict[image_path] = sess.run(\n",
        "                    [module_outputs['locations'], module_outputs['descriptors']],\n",
        "                    feed_dict={image_placeholder: image})\n",
        "      #########################################################################################################################          \n",
        "        def compute_locations_and_descriptors(image_path):\n",
        "            tf.reset_default_graph()\n",
        "            tf.logging.set_verbosity(tf.logging.FATAL)\n",
        "\n",
        "            m = hub.Module('https://tfhub.dev/google/delf/1')\n",
        "\n",
        "            # The module operates on a single image at a time, so define a placeholder to\n",
        "            # feed an arbitrary image in.\n",
        "            image_placeholder = tf.placeholder(\n",
        "                tf.float32, shape = (None, None, 3), name = 'input_image')\n",
        "\n",
        "            module_inputs = {\n",
        "                'image': image_placeholder,\n",
        "                'score_threshold': 100.0,\n",
        "                'image_scales': [0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0],\n",
        "                'max_feature_num': 1000,\n",
        "            }\n",
        "\n",
        "            module_outputs = m(module_inputs, as_dict=True)\n",
        "\n",
        "            def image_input_fn(image_files):\n",
        "              filename_queue = tf.train.string_input_producer(\n",
        "                  image_files, shuffle=False)\n",
        "              reader = tf.WholeFileReader()\n",
        "              _, value = reader.read(filename_queue)\n",
        "              image_tf = tf.image.decode_jpeg(value, channels=3)\n",
        "              return tf.image.convert_image_dtype(image_tf, tf.float32)\n",
        "\n",
        "            image_tf = image_input_fn([image_path])\n",
        "\n",
        "            with tf.train.MonitoredSession() as sess:\n",
        "                image = sess.run(image_tf)\n",
        "                #print('Extracting locations and descriptors from %s' % image_path)\n",
        "                return sess.run(\n",
        "                    [module_outputs['locations'], module_outputs['descriptors']],\n",
        "                    feed_dict={image_placeholder: image})\n",
        "            \n",
        "    ###############################################################################################################################\n",
        "        locations_agg = np.concatenate([results_dict[img][0] for img in db_images])\n",
        "        descriptors_agg = np.concatenate([results_dict[img][1] for img in db_images])\n",
        "        for desc in locations_agg:\n",
        "              num_features = locations_agg.shape[0]\n",
        "              #print(\"DB image has %d features\" % num_features)\n",
        "        accumulated_indexes_boundaries = list(accumulate([results_dict[img][0].shape[0] for img in db_images]))\n",
        "        \n",
        "    ###############################################################################################################################\n",
        "        d_tree = cKDTree(descriptors_agg) # build the KD tree\n",
        "        \n",
        "    ###############################################################################################################################\n",
        "        query_image = '/content/Data/test_images/%s.jpg'%(test_image_id)\n",
        "        #query_image= '/content/Data/test_images/5f516881e61501c4.jpg'\n",
        "        #query_image= '/content/Data/test_images/5f516881e61501c4.jpg'\n",
        "        def preprocess_query_image(imagepath):\n",
        "            '''\n",
        "            Resize the query image and return the resized image path.\n",
        "            '''\n",
        "            query_temp_folder_name = 'query_temp_folder'\n",
        "            query_temp_folder = os.path.join(os.path.dirname(imagepath), query_temp_folder_name)\n",
        "            os.makedirs(query_temp_folder, exist_ok = True)\n",
        "            query_basename = os.path.basename(imagepath)\n",
        "            destfile = os.path.join(query_temp_folder, query_basename)\n",
        "            resized_image = resize_image(imagepath, destfile)\n",
        "            return resized_image\n",
        "\n",
        "        resized_image = preprocess_query_image(query_image)\n",
        "        \n",
        "    ###############################################################################################################################\n",
        "        query_image_locations, query_image_descriptors = compute_locations_and_descriptors(resized_image)\n",
        "        num_features_query = query_image_locations.shape[0]\n",
        "        print(\"Query image has %d features\" % num_features_query)\n",
        "        \n",
        "    ###############################################################################################################################\n",
        "        distance_threshold = 0.8\n",
        "        # K nearest neighbors\n",
        "        K = 10\n",
        "        distances, indices = d_tree.query(\n",
        "            query_image_descriptors, distance_upper_bound = distance_threshold, k = K, n_jobs = -1)\n",
        "\n",
        "        # Find the list of unique accumulated/aggregated indexes\n",
        "        unique_indices = np.array(list(set(indices.flatten())))\n",
        "\n",
        "        unique_indices.sort()\n",
        "        if unique_indices[-1] == descriptors_agg.shape[0]:\n",
        "            unique_indices = unique_indices[:-1]\n",
        "            \n",
        "    ###############################################################################################################################\n",
        "        unique_image_indexes = np.array(\n",
        "            list(set([np.argmax([np.array(accumulated_indexes_boundaries) > index]) \n",
        "                      for index in unique_indices])))\n",
        "        unique_image_indexes\n",
        "        \n",
        "    ###############################################################################################################################\n",
        "        def image_index_2_accumulated_indexes(index, accumulated_indexes_boundaries):\n",
        "            '''\n",
        "            Image index to accumulated/aggregated locations/descriptors pair indexes.\n",
        "            '''\n",
        "            if index > len(accumulated_indexes_boundaries) - 1:\n",
        "                return None\n",
        "            accumulated_index_start = None\n",
        "            accumulated_index_end = None\n",
        "            if index == 0:\n",
        "                accumulated_index_start = 0\n",
        "                accumulated_index_end = accumulated_indexes_boundaries[index]\n",
        "            else:\n",
        "                accumulated_index_start = accumulated_indexes_boundaries[index-1]\n",
        "                accumulated_index_end = accumulated_indexes_boundaries[index]\n",
        "            return np.arange(accumulated_index_start,accumulated_index_end)\n",
        "        \n",
        "    ###############################################################################################################################\n",
        "        def get_locations_2_use(image_db_index, k_nearest_indices, accumulated_indexes_boundaries):\n",
        "            '''\n",
        "            Get a pair of locations to use, the query image to the database image with given index.\n",
        "            Return: a tuple of 2 numpy arrays, the locations pair.\n",
        "            '''\n",
        "            image_accumulated_indexes = image_index_2_accumulated_indexes(image_db_index, accumulated_indexes_boundaries)\n",
        "            locations_2_use_query = []\n",
        "            locations_2_use_db = []\n",
        "            for i, row in enumerate(k_nearest_indices):\n",
        "                for acc_index in row:\n",
        "                    if acc_index in image_accumulated_indexes:\n",
        "                        locations_2_use_query.append(query_image_locations[i])\n",
        "                        locations_2_use_db.append(locations_agg[acc_index])\n",
        "                        break\n",
        "            return np.array(locations_2_use_query), np.array(locations_2_use_db)\n",
        "        \n",
        "    ###############################################################################################################################\n",
        "        \n",
        "        # Array to keep track of all candidates in database.\n",
        "        inliers_counts = []\n",
        "        # Read the resized query image for plotting.\n",
        "        img_1 = mpimg.imread(resized_image)\n",
        "        comparison = 0\n",
        "        top3 = []\n",
        "        flag = 0\n",
        "        for index in unique_image_indexes:\n",
        "          \n",
        "          if comparison > 30:\n",
        "            break\n",
        "            \n",
        "          locations_2_use_query, locations_2_use_db = get_locations_2_use(index, indices, accumulated_indexes_boundaries)\n",
        "          # Perform geometric verification using RANSAC.\n",
        "          try:\n",
        "            _, inliers = ransac(\n",
        "                (locations_2_use_db, locations_2_use_query), # source and destination coordinates\n",
        "                AffineTransform,\n",
        "                min_samples = 3,\n",
        "                residual_threshold = 20,\n",
        "                max_trials = 1000)\n",
        "          except ValueError:\n",
        "            #print('no sample')\n",
        "            inliers = None\n",
        "            \n",
        "          # If no inlier is found for a database candidate image, we continue on to the next one.\n",
        "          if inliers is None or len(inliers) == 0:\n",
        "              continue\n",
        "          # the number of inliers as the score for retrieved images.\n",
        "          inliers_counts.append({\"index\": index, \"inliers\": sum(inliers)})\n",
        "          print('Found inliers for image {} -> {}'.format(index, sum(inliers)))\n",
        "          # Visualize correspondences.\n",
        "          _, ax = plt.subplots()\n",
        "          img_2 = mpimg.imread(db_images[index])\n",
        "          inlier_idxs = np.nonzero(inliers)[0]\n",
        "          plot_matches(\n",
        "              ax,\n",
        "              img_1,\n",
        "              img_2,\n",
        "              locations_2_use_db,\n",
        "              locations_2_use_query,\n",
        "              np.column_stack((inlier_idxs, inlier_idxs)),\n",
        "              matches_color = 'b')\n",
        "          ax.axis('off')\n",
        "          ax.set_title('DELF correspondences (class = {})'.format(class_folder))\n",
        "          plt.show()\n",
        "          \n",
        "      ###############################################################################################################################\n",
        "          inliers_list = []\n",
        "          for inl in inliers_counts:\n",
        "              inliers_list.append(inl['inliers'])\n",
        "\n",
        "          if len(inliers_list) > 0:\n",
        "              mean_features = mean(inliers_list)\n",
        "          else:\n",
        "              mean_features = 0\n",
        "          print(inliers_counts)\n",
        "          print(inliers_list)\n",
        "          print('Average number of inliers: {}'.format(mean(inliers_list)))\n",
        "          comparison += 1\n",
        "          if sum(inliers) >= 25:\n",
        "            csvfile.write('{0},{1},1,{2}\\n'.format(test_image_id, class_folder, prob))\n",
        "            \n",
        "            flag = 1\n",
        "            break\n",
        "\n",
        "\n",
        "        #deciding landmark or not based on threshold\n",
        "        if flag == 0:\n",
        "          inliers_list = sorted(inliers_list, reverse = True)\n",
        "          top3 = inliers_list[:3]\n",
        "          mean_max_inliers = mean(top3)\n",
        "          print('Mean value of top3 number of inliers found: {}'.format(mean_max_inliers))\n",
        "\n",
        "          if mean_max_inliers < 5: \n",
        "            csvfile.write('{0},{1},N,{2}\\n'.format(test_image_id, class_folder, prob))\n",
        "          else:\n",
        "            if mean_max_inliers > 8:\n",
        "              csvfile.write('{0},{1},1,{2}\\n'.format(test_image_id, class_folder, prob))\n",
        "            else:\n",
        "              csvfile.write('{0},{1},0,{2}\\n'.format(test_image_id, class_folder, prob))\n",
        "        \n",
        "        flag = 0            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxnaiuQnmYVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run this cell for every csv file created, changeing every time the input and output file\n",
        "#1--> '/content/Data/sub_spezifinal1.csv', '/content/Data/sub_spezifinal_delf1.csv'\n",
        "#2--> '/content/Data/sub_spezifinal2.csv', '/content/Data/sub_spezifinal_delf2.csv'\n",
        "#3--> '/content/Data/sub_spezifinal3.csv', '/content/Data/sub_spezifinal_delf3.csv'\n",
        "#4--> '/content/Data/sub_spezifinal4.csv', '/content/Data/sub_spezifinal_delf4.csv'\n",
        "#5--> '/content/Data/sub_spezifinal5.csv', '/content/Data/sub_spezifinal_delf5.csv'\n",
        "num_csv = 14 #every time add the right number \n",
        "subfile_input = '/content/Data/sub_spezifinal'\n",
        "subfile_output = '/content/Data/sub_spezifinal_delf'\n",
        "\n",
        "for i in range(0, num_csv):\n",
        "  input_file = subfile_input + str(i + 1) + '.csv'\n",
        "  output_file = subfile_output + str(i + 1) + '.csv'\n",
        "  DELF(input_file, output_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcL5LdRznYVy",
        "colab_type": "text"
      },
      "source": [
        "**Merge of DELF file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35tg5rv9nXqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "delf_final = '/content/Data/sub_spezifinal_delf_final.csv'\n",
        "subfile = '/content/Data/sub_spezifinal_delf' \n",
        "\n",
        "#delf_final = '/content/Data/sub_spezifinal_final.csv'\n",
        "#subfile = '/content/Data/sub_spezifinal'\n",
        "num_csv = 14 #every time add the right number \n",
        "\n",
        "with open(delf_final, 'w') as csvfile:\n",
        "  csvfile.write('id,landmark,match,prob\\n')\n",
        "  for i in range(0, num_csv):\n",
        "    csv_to_open = subfile + str(i + 1) + '.csv'\n",
        "    pred = pd.read_csv(csv_to_open)\n",
        "    for j in range(len(pred)):\n",
        "      csvfile.write('{0},{1},{2},{3}\\n'.format(pred['id'][j], pred['landmark'][j], pred['match'][j], pred['prob'][j]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vVUYGVxRdPJ",
        "colab_type": "text"
      },
      "source": [
        "**Computation of GAP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gknrgPUKRdxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "delf_results = pd.read_csv('/content/Data/sub_spezifinal_delf_final.csv')\n",
        "print(delf_results)\n",
        "N = len(delf_results)\n",
        "print('N = ', N)\n",
        "M = 0\n",
        "true_positive = 0\n",
        "false_positive = 0\n",
        "results = []\n",
        "gap_values = []\n",
        "for i in range(0, N):\n",
        "  match = delf_results['match'][i]\n",
        "  #print(match)\n",
        "  if(str(match) != 'N'):\n",
        "    M += 1\n",
        "    results.append([delf_results['id'][i], delf_results['landmark'][i], delf_results['match'][i], delf_results['prob'][i]])\n",
        "print('M = ', M)    \n",
        "\n",
        "results = sorted(results, key = lambda results: results[3], reverse = True)\n",
        "print(results)\n",
        "GAP = 0\n",
        "\n",
        "for i in range(M):\n",
        "  if(results[i][2] == '1'):\n",
        "    #print('caso == 1')\n",
        "    true_positive += 1\n",
        "    rel = 1\n",
        "    print('rel({}) = {}'.format(i, rel))\n",
        "  else:\n",
        "    #print(results[i][2])\n",
        "    if(results[i][2] == '0'):\n",
        "      #print('caso == 0')\n",
        "      false_positive += 1  \n",
        "      rel = 0\n",
        "      print('rel({}) = {}'.format(i, rel))\n",
        "\n",
        "  #if(true_positive != 0 and false_positive != 0):\n",
        "  P = true_positive / (true_positive + false_positive)\n",
        "  print('P({}) = {}'.format(i, P))\n",
        "  GAP += P*rel\n",
        "  gap_values.append(GAP/M)\n",
        "  print('GAP numerator: ', GAP)\n",
        "\n",
        "plt.plot(range(M), gap_values, 'r')\n",
        "#plt.legend(loc='best', labels = ('Accuracy on Train', 'Accuracy on Validation') )\n",
        "plt.xlabel('number of predictions')\n",
        "plt.title('GAP on test set')\n",
        "plt.grid()\n",
        "plt.show() \n",
        "\n",
        "GAP = (GAP/M)*100\n",
        "print('accuracy GAP: {}%'.format(GAP))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th3AcovfSIm3",
        "colab_type": "text"
      },
      "source": [
        "**DELF on two sample Images** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IopacKZMODpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMAGE_1_URL = 'https://images.unsplash.com/photo-1522184808165-a39a75502037?ixlib=rb-0.3.5&ixid=eyJhcHBfaWQiOjEyMDd9&s=9058a9f269234b4d7b6dc7bd7066d7e8&auto=format&fit=crop&w=1350&q=80'\n",
        "# IMAGE_2_URL = 'https://images.unsplash.com/photo-1479660656269-197ebb83b540?ixlib=rb-0.3.5&ixid=eyJhcHBfaWQiOjEyMDd9&s=88b85498e4c076fce0ed0c086543afb6&auto=format&fit=crop&w=1952&q=80'\n",
        "\n",
        "IMAGE_1_URL = '/content/Data/test_images_from_train/1140/814b5c99a1218cb3.jpg'\n",
        "IMAGE_2_URL = '/content/Data/test_images_from_train/1140/34347fabe6a816f8.jpg'\n",
        "\n",
        "\n",
        "# The names that will be used for the resized local images.\n",
        "\n",
        "IMAGE_1_JPG = 'image_1.jpg'\n",
        "IMAGE_2_JPG = 'image_2.jpg'\n",
        "\n",
        "#@title The images that will be processed by DELF\n",
        "def download_and_resize_image(url, filename, new_width=128, new_height=128):\n",
        "    if 'http' in url:\n",
        "        response = urlopen(url)\n",
        "        image_data = response.read()\n",
        "        pil_image = Image.open(BytesIO(image_data))\n",
        "    else:\n",
        "        pil_image = Image.open(url)\n",
        "    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "    pil_image_rgb = pil_image.convert('RGB')\n",
        "    pil_image_rgb.save(filename, format='JPEG', quality=90)\n",
        "\n",
        "download_and_resize_image(IMAGE_1_URL, IMAGE_1_JPG)\n",
        "download_and_resize_image(IMAGE_2_URL, IMAGE_2_JPG)\n",
        "\n",
        "def show_images(image_path_list):\n",
        "    plt.figure()\n",
        "    for i, image_path in enumerate(image_path_list):\n",
        "        plt.subplot(1, len(image_path_list), i+1)\n",
        "        plt.imshow(np.asarray(Image.open(image_path)))\n",
        "        plt.title(image_path)\n",
        "        plt.grid(False)\n",
        "        plt.yticks([])\n",
        "        plt.xticks([])\n",
        "    plt.show()\n",
        "\n",
        "show_images([IMAGE_1_JPG, IMAGE_2_JPG])\n",
        "\n",
        "def image_input_fn(image_files):\n",
        "    filename_queue = tf.train.string_input_producer(\n",
        "        image_files, shuffle=False)\n",
        "    reader = tf.WholeFileReader()\n",
        "    _, value = reader.read(filename_queue)\n",
        "    image_tf = tf.image.decode_jpeg(value, channels=3)\n",
        "    return tf.image.convert_image_dtype(image_tf, tf.float32)\n",
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "tf.logging.set_verbosity(tf.logging.FATAL)\n",
        "\n",
        "m = hub.Module('https://tfhub.dev/google/delf/1')\n",
        "\n",
        "# The module operates on a single image at a time, so define a placeholder to\n",
        "# feed an arbitrary image in.\n",
        "image_placeholder = tf.placeholder(\n",
        "    tf.float32, shape=(None, None, 3), name='input_image')\n",
        "\n",
        "module_inputs = {\n",
        "    'image': image_placeholder,\n",
        "    'score_threshold': 100.0,\n",
        "    'image_scales': [0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0],\n",
        "    'max_feature_num': 1000,\n",
        "}\n",
        "\n",
        "module_outputs = m(module_inputs, as_dict=True)\n",
        "\n",
        "image_tf = image_input_fn([IMAGE_1_JPG, IMAGE_2_JPG])\n",
        "\n",
        "with tf.train.MonitoredSession() as sess:\n",
        "    results_dict = {}  # Stores the locations and their descriptors for each image\n",
        "    for image_path in [IMAGE_1_JPG, IMAGE_2_JPG]:\n",
        "        image = sess.run(image_tf)\n",
        "        print('Extracting locations and descriptors from %s' % image_path)\n",
        "        results_dict[image_path] = sess.run(\n",
        "            [module_outputs['locations'], module_outputs['descriptors']],\n",
        "            feed_dict={image_placeholder: image})\n",
        "\n",
        "\n",
        "#@title TensorFlow is not needed for this post-processing and visualization\n",
        "def match_images(results_dict, image_1_path, image_2_path):\n",
        "    distance_threshold = 0.8\n",
        "\n",
        "    # Read features.\n",
        "    locations_1, descriptors_1 = results_dict[image_1_path]\n",
        "    num_features_1 = locations_1.shape[0]\n",
        "    print(\"Loaded image 1's %d features\" % num_features_1)\n",
        "    locations_2, descriptors_2 = results_dict[image_2_path]\n",
        "    num_features_2 = locations_2.shape[0]\n",
        "    print(\"Loaded image 2's %d features\" % num_features_2)\n",
        "\n",
        "    # Find nearest-neighbor matches using a KD tree.\n",
        "    d1_tree = cKDTree(descriptors_1)\n",
        "    _, indices = d1_tree.query(\n",
        "        descriptors_2, distance_upper_bound=distance_threshold)\n",
        "\n",
        "  # Select feature locations for putative matches.\n",
        "    locations_2_to_use = np.array([\n",
        "        locations_2[i,]\n",
        "        for i in range(num_features_2)\n",
        "        if indices[i] != num_features_1\n",
        "    ])\n",
        "    locations_1_to_use = np.array([\n",
        "        locations_1[indices[i],]\n",
        "        for i in range(num_features_2)\n",
        "        if indices[i] != num_features_1\n",
        "    ])\n",
        "\n",
        "  # Perform geometric verification using RANSAC.\n",
        "    _, inliers = ransac(\n",
        "        (locations_1_to_use, locations_2_to_use),\n",
        "        AffineTransform,\n",
        "        min_samples=3,\n",
        "        residual_threshold=20,\n",
        "        max_trials=1000)\n",
        "    # the number of inliers as the score for retrieved images.\n",
        "    print('Found %d inliers' % sum(inliers))\n",
        "\n",
        "    # Visualize correspondences.\n",
        "    _, ax = plt.subplots()\n",
        "    img_1 = mpimg.imread(image_1_path)\n",
        "    img_2 = mpimg.imread(image_2_path)\n",
        "    inlier_idxs = np.nonzero(inliers)[0]\n",
        "    plot_matches(\n",
        "        ax,\n",
        "        img_1,\n",
        "        img_2,\n",
        "        locations_1_to_use,\n",
        "        locations_2_to_use,\n",
        "        np.column_stack((inlier_idxs, inlier_idxs)),\n",
        "        matches_color='b')\n",
        "    ax.axis('off')\n",
        "    ax.set_title('DELF correspondences')\n",
        "    plt.figure(figsize=(18,24))\n",
        "    plt.show()\n",
        "\n",
        "match_images(results_dict, IMAGE_1_JPG, IMAGE_2_JPG)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}